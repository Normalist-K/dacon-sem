{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/dacon-epitope/dacon-sem')\n",
    "\n",
    "from src.datasets.sem_dataset import SEMDataset\n",
    "from src.datasets.sem_datamodule import SEMDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('/shared/Samsung/')\n",
    "simulation_sem_paths = os.path.join(data_path, 'simulation_data', 'SEM', '*', '*', '*.png')\n",
    "simulation_sem_paths = np.array(sorted(glob(simulation_sem_paths)))\n",
    "simulation_depth_paths = os.path.join(data_path, 'simulation_data', 'Depth', '*', '*', '*.png')\n",
    "simulation_depth_paths = np.array(sorted(glob(simulation_depth_paths) + glob(simulation_depth_paths)))\n",
    "data_len = len(simulation_sem_paths)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "splitlist = list(skf.split(range(data_len),[0]*data_len))\n",
    "\n",
    "train_index = splitlist[0][0]\n",
    "valid_index = splitlist[0][1]\n",
    "\n",
    "train_sem_paths = simulation_sem_paths[train_index]\n",
    "train_depth_paths = simulation_depth_paths[train_index]\n",
    "\n",
    "valid_sem_paths = simulation_sem_paths[valid_index]\n",
    "valid_depth_paths = simulation_depth_paths[valid_index]\n",
    "\n",
    "test_sem_paths = os.path.join(data_path, 'test', 'SEM', '*.png')\n",
    "test_sem_paths = np.array(sorted(glob(test_sem_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(resize):\n",
    "    label_transform = A.Compose([\n",
    "        A.Resize(resize[0], resize[1], always_apply=True),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.Normalize(mean=[0.5],std=[0.5]),\n",
    "        A.Resize(resize[0], resize[1], always_apply=True),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return transform, label_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_sample_path = train_sem_paths[0]\n",
    "depth_sample_path = train_depth_paths[0]\n",
    "\n",
    "sem_img = cv2.imread(sem_sample_path, cv2.IMREAD_GRAYSCALE)\n",
    "depth_img = cv2.imread(depth_sample_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(96, 64, always_apply=True),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                       scale_limit=0.1, \n",
    "                       rotate_limit=5, \n",
    "                       p=0.5),\n",
    "    # A.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "    A.Normalize(mean=[0.5],std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transformed = transform(image=sem_img, mask=depth_img)\n",
    "transformed_image = transformed['image']\n",
    "transformed_mask = transformed['mask']\n",
    "\n",
    "imgs = [sem_img, transformed_image, transformed_mask]\n",
    "\n",
    "# def display_images(imgs):\n",
    "#     for i in range(len(imgs)):\n",
    "#         plt.subplot(1, len(imgs), i+1)\n",
    "#         plt.imshow(imgs[i])\n",
    "#     plt.title(os.path.basename(sem_sample_path))\n",
    "\n",
    "# display_images(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 64])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_mask.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 64])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, label_transform = get_transform([96, 64])\n",
    "\n",
    "small_len = len(train_sem_paths) // 10\n",
    "data_train = SEMDataset(train_sem_paths[:small_len], train_depth_paths[:small_len], transform, label_transform)\n",
    "data_test = SEMDataset(test_sem_paths, None, transform, label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('torch18')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98f3181f4900a3173dff2251935f87d1f345563f3a07cb125f858d750ad52894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
